{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > The new form of the prolem can be described in terms of a game which we call the \"imitation game\". It is played with three people,\n",
    "a man(A), a woman(B), and an interroagtor(C) who may be of either sex. The interragator stays in a room a part fron the other tow.The\n",
    "object of the game for the interrogator is to determine which of the other two is the man and which is the woman.\n",
    "    We now ask the question, \"What will happen when a machine takes the part A in this game?\" Will the interrogator decide wrongly \n",
    "as often when the game is played like this as he does when the game is played between a man and a woman ? These questions replace our original, \n",
    "\"Can machines think?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 许多机器学习系统解决的都是无法直接使用固定规则或者流程代码完成的问题。\n",
    "- 具备“学习”能力的程序都是指它能够不断的从经历和数据中西区经验教训，从而应对未来的预测任务。我们把这种对未知的预测能力叫做泛化力（Generalization）\n",
    "- 具备不断改善自身应对具体任务的能力。这种完成任务的能力叫性能（Performance）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 机器学习定义(Tom Mitchell): <br>\n",
    "A program can be said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T ,as measured by\n",
    "    P , improves with experience E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 良/恶性乳腺癌肿瘤预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy(10 training samples): 0.8685714285714285\n",
      "[-1.51522787]\n",
      "[-0.10721332  0.48314152]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy(10 training samples): 0.9371428571428572\n",
      "[-4.67611309]\n",
      "[0.59071861 0.7498354 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_train = pd.read_csv('./Datasets/Breast-Cancer/breast-cancer-train.csv')\n",
    "# print(df_train)\n",
    "\n",
    "df_test = pd.read_csv('./Datasets/Breast-Cancer/breast-cancer-test.csv')\n",
    "# print(df_test)\n",
    "\n",
    "df_test_negative = df_test.loc[df_test['Type'] == 0][[\n",
    "    'Clump Thickness', 'Cell Size'\n",
    "]]\n",
    "df_test_positive = df_test.loc[df_test['Type'] == 1][[\n",
    "    'Clump Thickness', 'Cell Size'\n",
    "]]\n",
    "# print(df_test_negative)\n",
    "# print(df_test_positive)\n",
    "\n",
    "plt.scatter(\n",
    "    df_test_negative['Clump Thickness'],\n",
    "    df_test_negative['Cell Size'],\n",
    "    marker='o',\n",
    "    s=200,\n",
    "    c='red')\n",
    "plt.scatter(\n",
    "    df_test_positive['Clump Thickness'],\n",
    "    df_test_positive['Cell Size'],\n",
    "    marker='x',\n",
    "    s=150,\n",
    "    c='black')\n",
    "plt.xlabel('Clump Thickness')\n",
    "plt.ylabel('Cell Size')\n",
    "\n",
    "# 绘制随机直线\n",
    "# 截距\n",
    "intercept = np.random.random([1])\n",
    "# 系数\n",
    "coef = np.random.random([2])\n",
    "# print(intercept)\n",
    "# print(coef)\n",
    "lx = np.arange(0, 12)\n",
    "ly = (-intercept - lx * coef[0]) / coef[1]\n",
    "plt.plot(lx, ly, c='blue')\n",
    "\n",
    "# 第一次绘制，随意一条直线\n",
    "plt.show()\n",
    "\n",
    "# =====================引入逻辑斯蒂回归分类器：使用一小部分的训练集的数据看看初步效果=============================\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_train[['Clump Thickness', 'Cell Size']][:10], df_train['Type'][:10])\n",
    "print('Testing accuracy(10 training samples):', lr.score(df_test[['Clump Thickness', 'Cell Size']],df_test['Type']))\n",
    "\n",
    "intercept = lr.intercept_\n",
    "coef = lr.coef_[0,:]\n",
    "print(intercept)\n",
    "print(coef)\n",
    "ly = (-intercept - lx * coef[0]) / coef[1]\n",
    "\n",
    "\n",
    "plt.scatter(\n",
    "    df_test_negative['Clump Thickness'],\n",
    "    df_test_negative['Cell Size'],\n",
    "    marker='o',\n",
    "    s=200,\n",
    "    c='red')\n",
    "plt.scatter(\n",
    "    df_test_positive['Clump Thickness'],\n",
    "    df_test_positive['Cell Size'],\n",
    "    marker='x',\n",
    "    s=150,\n",
    "    c='black')\n",
    "plt.xlabel('Clump Thickness')\n",
    "plt.ylabel('Cell Size')\n",
    "\n",
    "plt.plot(lx, ly, c='blue')\n",
    "# 引入逻辑回归算法生成的系数之后，虽然只用了小部分的训练数据，但区分效果已经好多了\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# =====================引入逻辑斯蒂回归分类器：使用全部的训练集的数据看看最终效果=============================\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_train[['Clump Thickness', 'Cell Size']], df_train['Type'])\n",
    "print('Testing accuracy(10 training samples):', lr.score(df_test[['Clump Thickness', 'Cell Size']],df_test['Type']))\n",
    "\n",
    "intercept = lr.intercept_\n",
    "coef = lr.coef_[0,:]\n",
    "print(intercept)\n",
    "print(coef)\n",
    "ly = (-intercept - lx * coef[0]) / coef[1]\n",
    "\n",
    "\n",
    "plt.scatter(\n",
    "    df_test_negative['Clump Thickness'],\n",
    "    df_test_negative['Cell Size'],\n",
    "    marker='o',\n",
    "    s=200,\n",
    "    c='red')\n",
    "plt.scatter(\n",
    "    df_test_positive['Clump Thickness'],\n",
    "    df_test_positive['Cell Size'],\n",
    "    marker='x',\n",
    "    s=150,\n",
    "    c='black')\n",
    "plt.xlabel('Clump Thickness')\n",
    "plt.ylabel('Cell Size')\n",
    "\n",
    "plt.plot(lx, ly, c='blue')\n",
    "# 引入逻辑回归算法生成的系数之后，虽然只用了小部分的训练数据，但区分效果已经好多了\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取在线数据、清除维度缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sample code number  Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class\n",
      "0               1000025                5                        1                         1                  1                            2           1                3                1        1      2\n",
      "1               1002945                5                        4                         4                  5                            7          10                3                2        1      2\n",
      "2               1015425                3                        1                         1                  1                            2           2                3                1        1      2\n",
      "3               1016277                6                        8                         8                  1                            3           4                3                7        1      2\n",
      "4               1017023                4                        1                         1                  3                            2           1                3                1        1      2\n",
      "5               1017122                8                       10                        10                  8                            7          10                9                7        1      4\n",
      "6               1018099                1                        1                         1                  1                            2          10                3                1        1      2\n",
      "7               1018561                2                        1                         2                  1                            2           1                3                1        1      2\n",
      "8               1033078                2                        1                         1                  1                            2           1                1                1        5      2\n",
      "9               1033078                4                        2                         1                  1                            2           1                2                1        1      2\n",
      "10              1035283                1                        1                         1                  1                            1           1                3                1        1      2\n",
      "11              1036172                2                        1                         1                  1                            2           1                2                1        1      2\n",
      "12              1041801                5                        3                         3                  3                            2           3                4                4        1      4\n",
      "13              1043999                1                        1                         1                  1                            2           3                3                1        1      2\n",
      "14              1044572                8                        7                         5                 10                            7           9                5                5        4      4\n",
      "15              1047630                7                        4                         6                  4                            6           1                4                3        1      4\n",
      "16              1048672                4                        1                         1                  1                            2           1                2                1        1      2\n",
      "17              1049815                4                        1                         1                  1                            2           1                3                1        1      2\n",
      "18              1050670               10                        7                         7                  6                            4          10                4                1        2      4\n",
      "19              1050718                6                        1                         1                  1                            2           1                3                1        1      2\n",
      "20              1054590                7                        3                         2                 10                            5          10                5                4        4      4\n",
      "21              1054593               10                        5                         5                  3                            6           7                7               10        1      4\n",
      "22              1056784                3                        1                         1                  1                            2           1                2                1        1      2\n",
      "24              1059552                1                        1                         1                  1                            2           1                3                1        1      2\n",
      "25              1065726                5                        2                         3                  4                            2           7                3                6        1      4\n",
      "26              1066373                3                        2                         1                  1                            1           1                2                1        1      2\n",
      "27              1066979                5                        1                         1                  1                            2           1                2                1        1      2\n",
      "28              1067444                2                        1                         1                  1                            2           1                2                1        1      2\n",
      "29              1070935                1                        1                         3                  1                            2           1                1                1        1      2\n",
      "30              1070935                3                        1                         1                  1                            1           1                2                1        1      2\n",
      "..                  ...              ...                      ...                       ...                ...                          ...         ...              ...              ...      ...    ...\n",
      "669             1350423                5                       10                        10                  8                            5           5                7               10        1      4\n",
      "670             1352848                3                       10                         7                  8                            5           8                7                4        1      4\n",
      "671             1353092                3                        2                         1                  2                            2           1                3                1        1      2\n",
      "672             1354840                2                        1                         1                  1                            2           1                3                1        1      2\n",
      "673             1354840                5                        3                         2                  1                            3           1                1                1        1      2\n",
      "674             1355260                1                        1                         1                  1                            2           1                2                1        1      2\n",
      "675             1365075                4                        1                         4                  1                            2           1                1                1        1      2\n",
      "676             1365328                1                        1                         2                  1                            2           1                2                1        1      2\n",
      "677             1368267                5                        1                         1                  1                            2           1                1                1        1      2\n",
      "678             1368273                1                        1                         1                  1                            2           1                1                1        1      2\n",
      "679             1368882                2                        1                         1                  1                            2           1                1                1        1      2\n",
      "680             1369821               10                       10                        10                 10                            5          10               10               10        7      4\n",
      "681             1371026                5                       10                        10                 10                            4          10                5                6        3      4\n",
      "682             1371920                5                        1                         1                  1                            2           1                3                2        1      2\n",
      "683              466906                1                        1                         1                  1                            2           1                1                1        1      2\n",
      "684              466906                1                        1                         1                  1                            2           1                1                1        1      2\n",
      "685              534555                1                        1                         1                  1                            2           1                1                1        1      2\n",
      "686              536708                1                        1                         1                  1                            2           1                1                1        1      2\n",
      "687              566346                3                        1                         1                  1                            2           1                2                3        1      2\n",
      "688              603148                4                        1                         1                  1                            2           1                1                1        1      2\n",
      "689              654546                1                        1                         1                  1                            2           1                1                1        8      2\n",
      "690              654546                1                        1                         1                  3                            2           1                1                1        1      2\n",
      "691              695091                5                       10                        10                  5                            4           5                4                4        1      4\n",
      "692              714039                3                        1                         1                  1                            2           1                1                1        1      2\n",
      "693              763235                3                        1                         1                  1                            2           1                2                1        2      2\n",
      "694              776715                3                        1                         1                  1                            3           2                1                1        1      2\n",
      "695              841769                2                        1                         1                  1                            2           1                1                1        1      2\n",
      "696              888820                5                       10                        10                  3                            7           3                8               10        2      4\n",
      "697              897471                4                        8                         6                  4                            3           4               10                6        1      4\n",
      "698              897471                4                        8                         8                  5                            4           5               10                4        1      4\n",
      "\n",
      "[683 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入pandas与numpy工具包。\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"max_columns\",1000) \n",
    "pd.set_option(\"display.width\",400)\n",
    "\n",
    "# 创建特征列表。\n",
    "column_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "\n",
    "# 使用pandas.read_csv函数从互联网读取指定数据。\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', names = column_names )\n",
    "\n",
    "# 将?替换为标准缺失值表示。\n",
    "data = data.replace(to_replace='?', value=np.nan)\n",
    "# 丢弃带有缺失值的数据（只要有一个维度有缺失）。\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "# 输出data的数据量和维度。\n",
    "data.shape\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性分类器：逻辑斯蒂回归模型、随机参数估计模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(683, 11)\n",
      "(512, 9)\n",
      "(171, 9)\n",
      "(512,)\n",
      "(171,)\n",
      "2    344\n",
      "4    168\n",
      "Name: Class, dtype: int64\n",
      "2    100\n",
      "4     71\n",
      "Name: Class, dtype: int64\n",
      "================================================================\n",
      "     Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses\n",
      "662                1                        1                         3                  1                            2           1                2                1        1\n",
      "282                1                        4                         3                 10                            4          10                5                6        1\n",
      "542                5                        3                         1                  1                            2           1                1                1        1\n",
      "301                1                        1                         1                  1                            2           1                3                1        1\n",
      "95                 1                        1                         1                  1                            2           1                3                1        1\n",
      "591                2                        5                         7                  6                            4          10                7                6        1\n",
      "356                5                        3                         3                  1                            3           3                3                3        3\n",
      "17                 4                        1                         1                  1                            2           1                3                1        1\n",
      "582                6                       10                         5                  5                            4          10                6               10        1\n",
      "460                5                        1                         1                  3                            2           1                1                1        1\n",
      "426                5                        3                         6                  1                            2           1                1                1        1\n",
      "693                3                        1                         1                  1                            2           1                2                1        2\n",
      "148                3                        1                         1                  3                            8           1                5                8        1\n",
      "597                5                        1                         3                  1                            2           1                3                1        1\n",
      "377                1                        1                         1                  1                            1           1                2                1        1\n",
      "193                1                        1                         1                  1                            2           1                3                1        1\n",
      "578                1                        1                         1                  1                            2           1                2                1        1\n",
      "306                1                        1                         1                  1                            2           1                3                1        1\n",
      "98                 9                        6                         9                  2                           10           6                2                9       10\n",
      "325                3                        2                         2                  1                            2           1                2                3        1\n",
      "198                1                        1                         1                  1                            2           1                1                1        1\n",
      "44                10                       10                        10                  4                            8           1                8               10        1\n",
      "429                2                        1                         1                  1                            2           1                2                1        1\n",
      "313                1                        1                         1                  1                            2           1                1                1        1\n",
      "74                10                        6                         4                  1                            3           4                3                2        3\n",
      "640                4                        1                         1                  3                            2           1                1                1        1\n",
      "549                7                        8                         3                  7                            4           5                7                8        2\n",
      "367                5                        8                         8                 10                            5          10                8               10        3\n",
      "121                4                        2                         1                  1                            2           2                3                1        1\n",
      "570                8                       10                         4                  4                            8          10                8                2        1\n",
      "..               ...                      ...                       ...                ...                          ...         ...              ...              ...      ...\n",
      "216                1                        1                         1                  1                            2           1                2                1        1\n",
      "534                2                        1                         1                  1                            2           1                2                1        1\n",
      "594                4                        8                         6                  3                            4          10                7                1        1\n",
      "666                5                        2                         2                  2                            2           1                1                1        2\n",
      "7                  2                        1                         2                  1                            2           1                3                1        1\n",
      "610               10                        4                         3                 10                            3          10                7                1        2\n",
      "101                2                        3                         4                  4                            2           5                2                5        1\n",
      "550                3                        1                         1                  1                            2           1                2                1        1\n",
      "418                5                        2                         2                  2                            2           2                3                2        2\n",
      "358                8                       10                         5                  3                            8           4                4               10        3\n",
      "86                 3                        3                         6                  4                            5           8                4                4        1\n",
      "543                4                        1                         1                  1                            2           1                2                1        1\n",
      "254                9                       10                        10                  1                           10           8                3                3        1\n",
      "630                6                        2                         3                  1                            2           1                1                1        1\n",
      "607                1                        1                         1                  1                            2           1                1                1        1\n",
      "678                1                        1                         1                  1                            2           1                1                1        1\n",
      "409                3                        1                         2                  1                            2           1                2                1        1\n",
      "178                4                        1                         1                  1                            2           1                3                1        1\n",
      "558                2                        1                         1                  1                            2           1                2                1        1\n",
      "560                5                        1                         1                  1                            2           1                3                1        1\n",
      "413                5                        1                         2                  1                            2           1                3                1        1\n",
      "63                 6                        3                         4                  1                            5           2                3                9        1\n",
      "104               10                       10                        10                 10                           10           1                8                8        8\n",
      "201               10                        8                         8                  4                           10          10                8                1        1\n",
      "59                 9                        5                         5                  2                            2           2                5                1        1\n",
      "207                1                        1                         1                  1                            1           1                3                1        1\n",
      "674                1                        1                         1                  1                            2           1                2                1        1\n",
      "593                5                        1                         2                  1                            2           1                1                1        1\n",
      "405                1                        1                         1                  1                            2           1                2                1        1\n",
      "20                 7                        3                         2                 10                            5          10                5                4        4\n",
      "\n",
      "[512 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn.cross_valiation里的train_test_split模块用于分割数据。\n",
    "# train_test_split 包路径改了\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机采样25%的数据用于测试，剩下的75%用于构建训练集合。\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[column_names[1:10]], data[column_names[10]], test_size=0.25, random_state=33)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "print(data.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# 测试集合里面肿瘤数据统计分布\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "print(\"=\" * 64)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.19196677 -0.68788787 -0.03809494 ... -0.55666054 -0.58626819\n",
      "  -0.34343195]\n",
      " [-1.19196677  0.30608745 -0.03809494 ...  0.68611648  1.09441105\n",
      "  -0.34343195]\n",
      " [ 0.24231522 -0.02523765 -0.72246721 ... -0.97091955 -0.58626819\n",
      "  -0.34343195]\n",
      " ...\n",
      " [ 0.24231522 -0.68788787 -0.38028108 ... -0.97091955 -0.58626819\n",
      "  -0.34343195]\n",
      " [-1.19196677 -0.68788787 -0.72246721 ... -0.55666054 -0.58626819\n",
      "  -0.34343195]\n",
      " [ 0.95945621 -0.02523765 -0.38028108 ...  0.68611648  0.42213936\n",
      "   1.42674078]]\n",
      "(512, 9)\n",
      "[[ 0.24231522  0.30608745  0.64627733 ... -0.14240153  1.09441105\n",
      "  -0.34343195]\n",
      " [-0.47482578 -0.68788787 -0.72246721 ... -0.55666054 -0.58626819\n",
      "  -0.34343195]\n",
      " [ 2.03516771  1.63138788  1.67283574 ...  0.27185747  1.76668275\n",
      "   4.96708623]\n",
      " ...\n",
      " [-0.11625528 -0.68788787 -0.72246721 ... -0.55666054 -0.58626819\n",
      "  -0.34343195]\n",
      " [ 2.03516771  1.96271298  1.67283574 ...  1.51463449  2.43895444\n",
      "   0.8366832 ]\n",
      " [ 2.03516771  0.30608745  1.3306496  ...  1.10037549 -0.58626819\n",
      "  -0.34343195]]\n",
      "(171, 9)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.preprocessing里导入StandardScaler。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 从sklearn.linear_model里导入LogisticRegression与SGDClassifier。\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 标准化数据，保证每个维度的特征数据方差为1，均值为0。使得预测结果不会被某些维度过大的特征值而主导。\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 4 4 2 2 2 4 2 2 2 2 4 2 4 4 4 4 4 2 2 4 4 2 4 4 2 2 4 4 4 4 4 4 4 4 2\n",
      " 4 4 4 4 4 2 4 2 2 4 2 2 4 4 2 2 2 4 2 2 2 2 2 4 4 2 2 2 4 2 2 2 2 4 2 2 2\n",
      " 2 2 2 4 4 2 2 2 4 2 2 2 4 2 4 2 4 4 2 2 2 2 4 4 2 2 2 4 2 2 4 2 2 2 2 2 4\n",
      " 2 2 2 2 2 2 4 2 2 4 4 2 4 2 2 2 4 2 2 4 4 2 4 4 2 2 2 2 4 2 4 2 4 2 2 2 2\n",
      " 2 4 4 2 4 4 2 4 2 2 2 2 4 4 4 2 4 2 2 4 2 4 4]\n",
      "(171,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 初始化LogisticRegression与SGDClassifier。\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "# 调用LogisticRegression中的fit函数/模块用来训练模型参数。\n",
    "lr.fit(X_train, y_train)\n",
    "# 使用训练好的模型lr对X_test进行预测，结果储存在变量lr_y_predict中。\n",
    "lr_y_predict = lr.predict(X_test)\n",
    "print(lr_y_predict)\n",
    "print(lr_y_predict.shape)\n",
    "# 调用SGDClassifier中的fit函数/模块用来训练模型参数。\n",
    "sgdc.fit(X_train, y_train)\n",
    "# 使用训练好的模型sgdc对X_test进行预测，结果储存在变量sgdc_y_predict中。\n",
    "sgdc_y_predict = sgdc.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LR Classifier: 0.9883040935672515\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.99      0.99      0.99       100\n",
      "   Malignant       0.99      0.99      0.99        71\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "=========================================================\n",
      "Accuarcy of SGD Classifier: 0.9883040935672515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      0.98      0.99       100\n",
      "   Malignant       0.97      1.00      0.99        71\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.metrics里导入classification_report模块。\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 使用逻辑斯蒂回归模型自带的评分函数score获得模型在测试集上的准确性结果。\n",
    "print('Accuracy of LR Classifier:', lr.score(X_test, y_test))\n",
    "print(\"=========================================================\")\n",
    "# 利用classification_report模块获得LogisticRegression其他三个指标的结果。\n",
    "print(classification_report(y_test, lr_y_predict, target_names=['Benign', 'Malignant']))\n",
    "print(\"=========================================================\")\n",
    " # 使用随机梯度下降模型自带的评分函数score获得模型在测试集上的准确性结果。\n",
    "print('Accuarcy of SGD Classifier:', sgdc.score(X_test, y_test))\n",
    "# 利用classification_report模块获得SGDClassifier其他三个指标的结果。\n",
    "print(classification_report(y_test, sgdc_y_predict, target_names=['Benign', 'Malignant']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机分类器 support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n",
      "[ 0.  0.  0.  4. 15. 12.  0.  0.  0.  0.  3. 16. 15. 14.  0.  0.  0.  0.\n",
      "  8. 13.  8. 16.  0.  0.  0.  0.  1.  6. 15. 11.  0.  0.  0.  1.  8. 13.\n",
      " 15.  1.  0.  0.  0.  9. 16. 16.  5.  0.  0.  0.  0.  3. 13. 16. 16. 11.\n",
      "  5.  0.  0.  0.  0.  3. 11. 16.  9.  0.]\n",
      "2\n",
      "(1797, 64)\n",
      "(1797, 64)\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.datasets里导入手写体数字加载器。\n",
    "from sklearn.datasets import load_digits\n",
    "# 从通过数据加载器获得手写体数字的数码图像数据并储存在digits变量中。\n",
    "digits = load_digits()\n",
    "print(digits)\n",
    "print(digits['data'][2])\n",
    "print(digits['target'][2])\n",
    "# 检视数据规模和特征维度。\n",
    "print(digits.data.shape)\n",
    "print(digits['data'].shape)\n",
    "print(digits['target'].shape)\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(450, 64)\n",
      "(1347,)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.cross_validation中导入train_test_split用于数据分割。\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机选取75%的数据作为训练样本；其余25%的数据作为测试样本。\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.preprocessing里导入数据标准化模块。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 从sklearn.svm里导入基于线性假设的支持向量机分类器LinearSVC。\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# 从仍然需要对训练和测试的特征数据进行标准化。\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "# 初始化线性假设的支持向量机分类器LinearSVC。\n",
    "lsvc = LinearSVC()\n",
    "#进行模型训练\n",
    "lsvc.fit(X_train, y_train)\n",
    "# 利用训练好的模型对测试样本的数字类别进行预测，预测结果储存在变量y_predict中。\n",
    "y_predict = lsvc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of Linear SVC is 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# 使用模型自带的评估函数进行准确性测评。\n",
    "print('The Accuracy of Linear SVC is', lsvc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       0.96      0.98      0.97        54\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       0.93      0.93      0.93        46\n",
      "           4       0.97      1.00      0.99        35\n",
      "           5       0.94      0.94      0.94        48\n",
      "           6       0.96      0.98      0.97        51\n",
      "           7       0.92      1.00      0.96        35\n",
      "           8       0.98      0.84      0.91        58\n",
      "           9       0.95      0.91      0.93        44\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       450\n",
      "   macro avg       0.95      0.96      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       0.96      0.98      0.97        54\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       0.93      0.93      0.93        46\n",
      "           4       0.97      1.00      0.99        35\n",
      "           5       0.94      0.94      0.94        48\n",
      "           6       0.96      0.98      0.97        51\n",
      "           7       0.92      1.00      0.96        35\n",
      "           8       0.98      0.84      0.91        58\n",
      "           9       0.95      0.91      0.93        44\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       450\n",
      "   macro avg       0.95      0.96      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 依然使用sklearn.metrics里面的classification_report模块对预测结果做更加详细的分析。\n",
    "from sklearn.metrics import classification_report\n",
    "print(digits.target_names.astype(str))\n",
    "print ( classification_report(y_test, y_predict, target_names=digits.target_names.astype(str)) )\n",
    "print ( classification_report(y_test, y_predict  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.datasets里导入新闻数据抓取器fetch_20newsgroups。\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# 与之前预存的数据不同，fetch_20newsgroups需要即时从互联网下载数据。\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "# 查验数据规模和细节。\n",
    "print(len(news.data))\n",
    "print( news.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.cross_validation 导入 train_test_split。\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 随机采样25%的数据样本作为测试集。\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.feature_extraction.text里导入用于文本特征向量转化模块。详细介绍请读者参考3.1.1.1 特征抽取一节。\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)\n",
    "\n",
    "# 从sklearn.naive_bayes里导入朴素贝叶斯模型。\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 从使用默认配置初始化朴素贝叶斯模型。\n",
    "mnb = MultinomialNB()\n",
    "# 利用训练数据对模型参数进行估计。\n",
    "mnb.fit(X_train, y_train)\n",
    "# 对测试样本进行类别预测，结果存储在变量y_predict中。\n",
    "y_predict = mnb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Naive Bayes Classifier is 0.8397707979626485\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       201\n",
      "           1       0.59      0.86      0.70       250\n",
      "           2       0.89      0.10      0.17       248\n",
      "           3       0.60      0.88      0.72       240\n",
      "           4       0.93      0.78      0.85       242\n",
      "           5       0.82      0.84      0.83       263\n",
      "           6       0.91      0.70      0.79       257\n",
      "           7       0.89      0.89      0.89       238\n",
      "           8       0.98      0.92      0.95       276\n",
      "           9       0.98      0.91      0.95       251\n",
      "          10       0.93      0.99      0.96       233\n",
      "          11       0.86      0.98      0.91       238\n",
      "          12       0.85      0.88      0.86       249\n",
      "          13       0.92      0.94      0.93       245\n",
      "          14       0.89      0.96      0.92       221\n",
      "          15       0.78      0.96      0.86       232\n",
      "          16       0.88      0.96      0.92       251\n",
      "          17       0.90      0.98      0.94       231\n",
      "          18       0.79      0.89      0.84       188\n",
      "          19       0.93      0.44      0.60       158\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      4712\n",
      "   macro avg       0.86      0.84      0.82      4712\n",
      "weighted avg       0.86      0.84      0.82      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.metrics里导入classification_report用于详细的分类性能报告。\n",
    "from sklearn.metrics import classification_report\n",
    "print('The accuracy of Naive Bayes Classifier is', mnb.score(X_test, y_test))\n",
    "print( classification_report(y_test, y_predict, target_names = news.target_names))\n",
    "print( classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K近邻(分类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.datasets 导入 iris数据加载器。\n",
    "from sklearn.datasets import load_iris\n",
    "# 使用加载器读取数据并且存入变量iris。\n",
    "iris = load_iris()\n",
    "# 查验数据规模。\n",
    "print(iris.data.shape)\n",
    "\n",
    "print(iris.data[:5])\n",
    "\n",
    "print(iris.DESCR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.cross_validation里选择导入train_test_split用于数据分割。\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 从使用train_test_split，利用随机种子random_state采样25%的数据作为测试集。\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=33)\n",
    "print(iris.target)\n",
    "# 結果0 1 2 代表了3中不同的亚种分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.preprocessing里选择导入数据标准化模块。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 从sklearn.neighbors里选择导入KNeighborsClassifier，即K近邻分类器。\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 对训练和测试的特征数据进行标准化。\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "# 使用K近邻分类器对测试数据进行类别预测，预测结果储存在变量y_predict中。\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train, y_train)\n",
    "y_predict = knc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of K-Nearest Neighbor Classifier is 0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         8\n",
      "  versicolor       0.73      1.00      0.85        11\n",
      "   virginica       1.00      0.79      0.88        19\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        38\n",
      "   macro avg       0.91      0.93      0.91        38\n",
      "weighted avg       0.92      0.89      0.90        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用模型自带的评估函数进行准确性测评。\n",
    "print('The accuracy of K-Nearest Neighbor Classifier is', knc.score(X_test, y_test) )\n",
    "\n",
    "# 依然使用sklearn.metrics里面的classification_report模块对预测结果做更加详细的分析。\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict, target_names=iris.target_names) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树-（泰坦尼克）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pandas用于数据分析。\n",
    "import pandas as pd\n",
    "# 利用pandas的read_csv模块直接从互联网收集泰坦尼克号乘客数据。\n",
    "titanic = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived                                             name      age     embarked                        home.dest room      ticket   boat     sex\n",
       "0          1    1st         1                     Allen, Miss Elisabeth Walton  29.0000  Southampton                     St Louis, MO  B-5  24160 L221      2  female\n",
       "1          2    1st         0                      Allison, Miss Helen Loraine   2.0000  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female\n",
       "2          3    1st         0              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male\n",
       "3          4    1st         0  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female\n",
       "4          5    1st         1                    Allison, Master Hudson Trevor   0.9167  Southampton  Montreal, PQ / Chesterville, ON  C22         NaN     11    male"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 观察一下前几行数据，可以发现，数据种类各异，数值型、类别型，甚至还有缺失数据。\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 11 columns):\n",
      "row.names    1313 non-null int64\n",
      "pclass       1313 non-null object\n",
      "survived     1313 non-null int64\n",
      "name         1313 non-null object\n",
      "age          633 non-null float64\n",
      "embarked     821 non-null object\n",
      "home.dest    754 non-null object\n",
      "room         77 non-null object\n",
      "ticket       69 non-null object\n",
      "boat         347 non-null object\n",
      "sex          1313 non-null object\n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 使用pandas，数据都转入pandas独有的dataframe格式（二维数据表格），直接使用info()，查看数据的统计特性。\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      "pclass    1313 non-null object\n",
      "age       633 non-null float64\n",
      "sex       1313 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 机器学习有一个不太被初学者重视，并且耗时，但是十分重要的一环，特征的选择，这个需要基于一些背景知识。根据我们对这场事故的了解，sex, age, pclass这些都很有可能是决定幸免与否的关键因素。\n",
    "X = titanic[['pclass', 'age', 'sex']]\n",
    "y = titanic['survived']\n",
    "\n",
    "# 对当前选择的特征进行探查。\n",
    "X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# 借由上面的输出，我们设计如下几个数据处理的任务：\n",
    "# 1) age这个数据列，只有633个，需要补完。\n",
    "# 2) sex 与 pclass两个数据列的值都是类别型的，需要转化为数值特征，用0/1代替。\n",
    "\n",
    "# 首先我们补充age里的数据，使用平均数或者中位数都是对模型偏离造成最小影响的策略。\n",
    "X['age'].fillna(X['age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      "pclass    1313 non-null object\n",
      "age       1313 non-null float64\n",
      "sex       1313 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 对补完的数据重新探查。\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由此得知，age特征得到了补完。\n",
    "\n",
    "# 数据分割。\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', 'sex=female', 'sex=male']\n",
      "[[31.19418104  0.          0.          1.          0.          1.        ]\n",
      " [31.19418104  1.          0.          0.          1.          0.        ]\n",
      " [31.19418104  0.          0.          1.          0.          1.        ]\n",
      " ...\n",
      " [12.          0.          1.          0.          1.          0.        ]\n",
      " [18.          0.          1.          0.          0.          1.        ]\n",
      " [31.19418104  0.          0.          1.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 我们使用scikit-learn.feature_extraction中的特征转换器，详见3.1.1.1特征抽取。\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse=False)\n",
    "\n",
    "# 转换特征后，我们发现凡是类别型的特征都单独剥离出来，独成一列特征，数值型的则保持不变。\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "print(vec.feature_names_)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样需要对测试数据的特征进行转换。\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从sklearn.tree中导入决策树分类器。\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 使用默认配置初始化决策树分类器。\n",
    "dtc = DecisionTreeClassifier()\n",
    "# 使用分割到的训练数据进行模型学习。\n",
    "dtc.fit(X_train, y_train)\n",
    "# 用训练好的决策树模型对测试特征数据进行预测。\n",
    "y_predict = dtc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.91      0.78      0.84       236\n",
      "    survived       0.58      0.80      0.67        93\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       329\n",
      "   macro avg       0.74      0.79      0.75       329\n",
      "weighted avg       0.81      0.78      0.79       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.metrics导入classification_report。\n",
    "from sklearn.metrics import classification_report\n",
    "# 输出预测准确性。\n",
    "print(dtc.score(X_test, y_test))\n",
    "# 输出更加详细的分类性能。\n",
    "print(classification_report(y_predict, y_test, target_names = ['died', 'survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 集成模型（分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
